{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "t3Snb5w82reH",
        "8XbufWay-x_t"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOxudqIOV9YnevRq+4cMet0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pkongla478/DSI200_Data-Visualization-Using-Python-/blob/main/DSI200_Data_Visualization_Using_Python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DSI200 Group Project: Data Visualization Using Python"
      ],
      "metadata": {
        "id": "t3Snb5w82reH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ผู้จัดทำ\n",
        "\n",
        "1.   นายวัชรนันท์ พันมูล เลขทะเบียนนักศึกษา 6524650071\n",
        "2.   นายวิภาสกร มั่นคงวิชญะ เลขทะเบียนนักศึกษา 6524651046 \n",
        "3.   นายนวัตกรณ์ แสงศิลา เลขทะเบียนนักศึกษา 6524651277 \n",
        "4.   นายปรัตถกร อุดมอานันท์ เลขทะเบียนนักศึกษา 6524651087"
      ],
      "metadata": {
        "id": "Qtsir7fR23gn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<i><b>ขั้นตอนที่ 1 </b></i>  `import  library`  ที่ต้องการนำมาใช้งาน\n",
        "- `Requests` -> ดึงข้อมูลทั้งหมดจากหน้า website\n",
        "- `Beautiful Soup` -> เป็น parse HTML เพื่อดึงข้อมูลจากไฟล์ HTML \n",
        "- `Pandas` -> จัดการ dataFrame และจัดการรูปแบบของข้อมูล\n",
        "- `seaborn`  -> เป็น libraly สำหรับการนำเสนอข้อมูลให้ออกมาในรูปแบบของ กราฟ แผนภูมิ และการนำเสนอข้อมูลรูปแบบต่างๆ\n",
        "- `matplotlib`  -> เป็น libraly ที่ไลบรารีที่ใช้ในการพลอตกราฟสองมิติจาก array\n",
        "- `numpy`  ->เป็น libraly เกี่ยวกับคณิตศาสตร์และการคำนวณเกี่ยวกับการจัดการข้อมูลชุด (Array) ขนาดใหญ่และเมทริกซ์\n",
        "- `warnings`  -> เป็น libraly ที่ ignore การแจ้งเตือน"
      ],
      "metadata": {
        "id": "6Qn6rV3j5hqU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests \n",
        "from bs4 import BeautifulSoup \n",
        "import pandas as pd\n",
        "import seaborn as sns \n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np  \n",
        "import warnings\n",
        "from pandas.core.common import  SettingWithCopyWarning\n",
        "warnings.simplefilter (action = \"ignore\", category =SettingWithCopyWarning)"
      ],
      "metadata": {
        "id": "yYm8k2BH6TT_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<i><b>ขั้นตอนที่ 2</b></i> ใส่ url ของ website ที่ต้องการ scrape \n",
        "\n",
        "\n",
        "> ในที่นี้ จะ scraping ข้อมูลจาก web page จำนวน 13 page \n",
        "ซึ่งทั้ง 13 page นั้น จะเป็นข้อมูลของระดับการศึกษา : ปริญญาตรี/โครงการพิเศษ ที่มีการประเมินในช่วงเกิดการระบาดของ Covid 19"
      ],
      "metadata": {
        "id": "4yXdl8hQ_hfJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "main_url1 = 'https://sgulyano.github.io/eval/' \n",
        "html_url1 = ['24363682.html', \n",
        "            '26742703.html', \n",
        "            '33561138.html', \n",
        "            '44868136.html',\n",
        "            '45435188.html', \n",
        "            '79550445.html', \n",
        "            '83255004.html', \n",
        "            '33565025.html', \n",
        "            '43951333.html', \n",
        "            '53231654.html', \n",
        "            '08846113.html', \n",
        "            '51435303.html',\n",
        "            '60189297.html'] \n",
        "     \n",
        "eval_url = [main_url1 + url for url in html_url1] #ทำการ loop เพื่อนำ main_url1 รวมกับ html_url1                                                        \n",
        "def get_table_data(item): #สร้างฟังก์ชัน get_table_data เพื่อดึงข้อมูลจากตารางใน web page  \n",
        "    data = [] #สร้าง listว่าง ที่ชื่อว่า data ไว้เก็บข้อมูล\n",
        "    table_body = item.find (\"tbody\") #ใน table_body ดึงข้อมูลของส่วน tbody ใน web page\n",
        "    rows = table_body.find_all (\"tr\") # ใน rows ดึงข้อมูลทั้งหมดของส่วน tr ที่อยู่ใน table_body\n",
        "    for row in rows : #สร้าง loop เพื่อดึงข้อมูลในส่วน td และ th ที่ต้องการ                                                                                                              \n",
        "        cols = row.find_all ([\"td\",\"th\"]) #ค้นหา tag HTML ที่มี ele ที่อยู่ใน tag td,tr\n",
        "        cols = [ele.text.strip() for ele in cols] #เป็น function ที่ loop ดึง ele มาทั้งหมด\n",
        "        data.append ([ele for ele in cols if ele]) #เก็บข้อมูลไว้ในตัวแปรที่ชื่อว่า data\n",
        "    return data #คืนค่า data ออกมา"
      ],
      "metadata": {
        "id": "waTT4UNP6V9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<i><b>ขั้นตอนที่ 3</b></i> ขั้นตอนการ scraping "
      ],
      "metadata": {
        "id": "C6PfYgTKAdWP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ดึงข้อมูล web page \n",
        "tb2sum = [] #กำหนดตัวแปร list เพื่อเก็บข้อมูล\n",
        "\n",
        "#function ปรับรูปแบบ DataFrame\n",
        "for page in range(12): #สร้าง function loop เพื่อดึงข้อมูลทั้ง 12 web page\n",
        "  res = requests.get(eval_url[page])\n",
        "  soup = BeautifulSoup(res.content, 'html.parser')\n",
        "  tables = soup.find_all('table')\n",
        "  tb2 = pd.DataFrame(get_table_data(tables[2])) #ดึงข้อมูลทั้งหมดจาก table ที่ 2 ของ web page\n",
        "  tb2.dropna(how =\"all\" ,inplace =True) #drop rows ที่มี missing value หรือ nan, n/a, None\n",
        "  tb2.columns = tb2.iloc [1,:] \n",
        "  rows = [0,1] #ระบุตำแหน่งของข้อมูล\n",
        "  tb2.drop (rows,axis = 0, inplace = True) #drop ข้อมูลที่ตำแหน่ง \n",
        "  tb2.dropna (inplace = True) #drop rows ที่มี missing value หรือ nan, n/a, None ทั้งหมด\n",
        "  tb2.drop (tb2[tb2.ที่.str.contains(\"รวม\")].index ,inplace = True) #drop rows ที่มีข้อมูลรวมและรวมทั้งหมด\n",
        "  tb0 = pd.DataFrame(get_table_data(tables[0]))\n",
        "  cols = [] #กำหนดตัวแปร list เพื่อเก็บข้อมูล\n",
        "  count = 5 #กำหนดจำนวนที่ต้องการ loop \n",
        "  for column in tb2.columns : #สร้าง function loop เพื่อเปลี่ยนแปลง format ของร้อยละ\n",
        "      if column == 'ร้อยละ' : #กำหนด format ใน column \n",
        "          cols.append(f'(ร้อยละ {count})') #คำสั่งแทนที่ด้วย object ร้อยละ \n",
        "          count -= 1 #คำสั่งลดจำนวนลงทีละ 1 เมื่อ loop \n",
        "          continue #คำสั่งบังคับให้โปรแกรมไปเริ่มต้นทำงานใหม่ที่จุดเริ่มต้นของลูป\n",
        "      cols.append (column) #คำสั่งสำหรับเพิ่มข้อมูลจาก column ลงในตัวแปร cols\n",
        "\n",
        "  tb2.columns = cols #เป็นการแสดงผลข้อมูลใน list จากตัวแปร cols\n",
        "  tb2.set_index (\"ที่\" ,inplace = True) #ลบ index \n",
        "  tb2['subject'] = tb0.iloc[0,1]\n",
        "  tb2['Sec./Gr.'] = tb0.iloc[1,1]\n",
        "  tb2['semester'] = tb0.iloc[2,1]\n",
        "  tb2['N'] = tb0.iloc[4,1]\n",
        "  tb2['n'] = tb0.iloc[5,1].split(' ')[0]\n",
        "  tb2sum.append(tb2)\n",
        "\n",
        "df2 = pd.concat(tb2sum) #นำข้อมูลทั้ง 12 web page ทั้งหมดมารวมกัน"
      ],
      "metadata": {
        "id": "DAlnZvLP8CBd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<i><b>ขั้นตอนที่ 4</b></i> ขั้นตอนการเปลี่ยน data type"
      ],
      "metadata": {
        "id": "cFQV31cZKPEf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#เปลี่ยน data type ของ df2 เป็น float\n",
        "for i in range(1,15):\n",
        "  df2.iloc[:,i]  = df2.iloc[:,i].astype(float)\n",
        "for i in [18,19]:\n",
        "  df2.iloc[:,i]  = df2.iloc[:,i].astype(float)"
      ],
      "metadata": {
        "id": "PlKNELu18XFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Visualization"
      ],
      "metadata": {
        "id": "8XbufWay-x_t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#รายวิชาใดที่มีคนทำแบบประเมินมากที่สุดในช่วงโควิด 19\n",
        "df3 = df2[['subject' , 'N' , 'n']]\n",
        "df3.drop_duplicates(inplace=True)\n",
        "df3 = df3.groupby('subject').sum()\n",
        "\n",
        "df3['n'].plot.bar()\n",
        "plt.title('Pra mern student')"
      ],
      "metadata": {
        "id": "nbjdR5NB-58Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#รายวิชาใดที่มีคนจดทะเบียนมากที่สุดในช่วงโควิด 19\n",
        "df3['N'].plot.bar()\n",
        "plt.title('All student')"
      ],
      "metadata": {
        "id": "5TZlzefM-81b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ใช้ X bar รวม เพื่อนำมา plot ดูการกระจายของข้อมูล ในแต่ละ section \n",
        "df3 = df2[['Sec./Gr.','X-Bar']]\n",
        "fig , ax =plt.subplots(1,3 , figsize = (25,6))\n",
        "plot = df3[df3['Sec./Gr.'] == '231863']\n",
        "ax[0].hist(x = plot['X-Bar'])\n",
        "ax[0].set_title('231863')\n",
        "\n",
        "plot = df3[df3['Sec./Gr.'] == '696574']\n",
        "ax[1].hist(x = plot['X-Bar'])\n",
        "ax[1].set_title('696574')\n",
        "\n",
        "plot = df3[df3['Sec./Gr.'] == '728025']\n",
        "ax[2].hist(x = plot['X-Bar'])\n",
        "ax[2].set_title('728025')"
      ],
      "metadata": {
        "id": "CMtKj7lz_Be4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ในช่วงที่เกิดการระบาดของ Covid-19 ข้อคำถามใดที่ได้รับการประเมินในระดับดีมาก มากที่สุด\n",
        "df3 = df2[['ข้อคำถาม','5']]\n",
        "df3 = df3.groupby('ข้อคำถาม').sum()\n",
        "df3['question'] = ['q{}'.format(x+1) for x in range(len(df3['5']))] \n",
        "df3.reset_index(inplace = True)\n",
        "plt.bar(x=df3['question'] , height=df3['5'])\n",
        "plt.title('Question Rating')"
      ],
      "metadata": {
        "id": "zNTK5VxS-_qE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#นำคำถามที่เกี่ยวข้องกับโควิด 19 (ข้อ 2,3) แต่ละรายวิชามาวัดผล ว่ารายวิชาใดที่มีการจัดการเรียนการสอนอย่างเหมาะสมกับสถานการณ์มากที่สุด\n",
        "df3 = df2[(df2['ข้อคำถาม']=='ผู้สอนมีการสอน ตามสภาพจริง เหมาะสมภายใต้ข้อจำกัดในสถานการณ์ COVID-19 และสอดคล้องกับมาตรฐานการเรียนรู้ / ตัวชี้วัด') | (df2['ข้อคำถาม'] == 'ผู้สอนมีการประเมินผล ตามสภาพจริง เหมาะสมภายใต้ข้อจำกัดในสถานการณ์ COVID-19 และสอดคล้องกับมาตรฐานการเรียนรู้ / ตัวชี้วัด' )]\n",
        "df3 = df3[['subject','5']]\n",
        "df3 = df3.groupby('subject').sum()\n",
        "df3.plot.bar()"
      ],
      "metadata": {
        "id": "KT3-Ge8H_E-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **สรุปผล**\n",
        "\n",
        "\n",
        "\n",
        "*   รายวิชาที่มีการจดทะเบียนมากที่สุด คือ FGL497 \n",
        "*   รายวิชาที่มีการประเมินมากที่สุด คือ FGL497 \n",
        "*   ในช่วงของการเกิดการระบาดของ covid 19 ข้อคำถามที่ได้รับการประเมินอยู่ในระดับดีมาก มากที่สุดคือ ข้อที่ 2 ผู้สอนมีการกำหนดวัตถุประสงค์, หัวข้อการสอน, และมีเอกสารอ่านประกอบ\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LY0BYrCoO6a2"
      }
    }
  ]
}